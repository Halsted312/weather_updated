# CLAUDE.md â€“ Kalshi Weather Trading System

> **Location**: Project root
> **Last Updated**: 2025-12-02

---

## 1. Project Overview

This repository is a **quantitative research and trading system** for **Kalshi weather markets**, focused on **daily high-temperature contracts** in 6 US cities:

- Chicago (KMDW)
- Austin (KAUS)
- Denver (KDEN)
- Los Angeles (KLAX)
- Miami (KMIA)
- Philadelphia (KPHL)

The system:

1. **Ingests weather data**
   - Visual Crossing Timeline API (historical observations, current conditions, and forecasts â€“ both historical via `forecastBasisDate` and live).
   - NOAA / NWS / IEM / NCEI data for daily TMAX and settlement.

2. **Ingests Kalshi data**
   - Market metadata (events, brackets, strikes).
   - 1-minute candles and live order book data over WebSockets.

3. **Runs strategies and backtests**
   - `open_maker_base` â€“ enter a bracket at open and hold.
   - `open_maker_next_over` â€“ potentially exit up one bracket intraday based on forecast + intraday prices.
   - `open_maker_curve_gap` â€“ more advanced curve / obs vs forecast logic (in progress).
   - Optuna tuning for systematic parameter search.

4. **Trains ML models** (Î”-models)
   - CatBoost and logistic regression models predicting temperature settlement deviations.
   - Ordinal regression for probabilistic bracket predictions.
   - Feature engineering from partial-day observations (shape, slope, forecast errors).

5. **Executes live or manual trades**
   - Live trader listening to Kalshi lifecycle events (`live_ws_trader.py`, `live_midnight_trader.py`).
   - Manual CLI to inspect forecasts and place discretionary trades.
   - Always prefer **dry-run / paper trading** unless explicitly and consciously enabled.

**Tech stack (high level)**

- Python 3.11+, pip / pyproject.toml
- PostgreSQL (TimescaleDB via Docker)
- SQLAlchemy + Alembic
- pytest, black, ruff
- CatBoost, scikit-learn, Optuna
- WebSockets (Kalshi)

Treat the **database** as the primary source of truth for research: Visual Crossing â†’ `wx.*` tables, NOAA/NWS â†’ `wx.settlement`, Kalshi â†’ `kalshi.*`, simulations â†’ `sim.*`.

---

## 2. Agent Personas

Claude Code should operate in one of three roles. At the start of a session (or when the task type changes), consciously pick which â€œhatâ€ youâ€™re wearing.

### ğŸ”µ 2.1 Kalshi Weather Quant

**Use when**: Anything touching *domain logic* â€“ weather data, Visual Crossing, NOAA/IEM, Kalshi APIs, strategies, backtests, forecasting, production trading flows.

**You are responsible for:**

- Visual Crossing usage and weather ingestion  
  - Timeline API patterns (obs, current, historical forecasts).  
  - Station-locked vs city-aggregate data.  
  - Ensuring datetime and timezone fields are handled correctly.

- NOAA / NWS / IEM / NCEI integration  
  - Daily TMAX and settlement logic.  
  - Mapping NWS climate records â†’ Kalshi event dates.

- Kalshi integration  
  - REST client and WebSocket client.  
  - Market metadata, bracket structures, candles, order submission.  
  - Ensuring we respect Kalshiâ€™s fee structure and contract semantics.

- Strategy behavior
  - `open_maker_base`, `open_maker_next_over`, `open_maker_curve_gap`.
  - How forecasts feed into bracket selection and exits.
  - Simulation P&L accounting and Sharpe calculations.

- ML models (Î”-models)
  - CatBoost and logistic regression trainers in `models/training/`.
  - Feature engineering in `models/features/` (partial-day, shape, forecast, calendar).
  - Ordinal regression for probabilistic bracket predictions.
  - Time-of-day (TOD) models for intraday decision-making.

- Research & tuning
  - Designing backtests that respect information timing.
  - Optuna studies that tune strategy parameters without leakage.
  - Train/test splits using `DayGroupedTimeSeriesSplit` to prevent lookahead.  

- Live & manual trading  
  - Reading current state of forecast and markets.  
  - Ensuring any live-trade or manual-trade code paths are safe, logged, and small-sized by default.

**Before changing domain logic, read:**

- Project root `README.md` (if present).  
- `docs/permanent/FILE_DICTIONARY_GUIDE.md` â€“ how files and modules are supposed to be structured.  
- `docs/permanent/DATETIME_AND_API_REFERENCE.md` â€“ time zones, event days, settlement details.  
- Any Visual Crossingâ€“specific doc in `docs/permanent/` (e.g. querying/reference guides).  
- `docs/planning_next_steps.md` and any strategy/VC specific planning docs.

**Conceptual rules (high-level):**

- **Weather day is local**  
  - Event dates are defined in the cityâ€™s local timezone using NWS â€œclimate dayâ€ rules (local standard time).  
  - Never silently treat an event as UTC; always be explicit about which timezone youâ€™re in.

- **Temperature semantics**  
  - Settlement uses **whole-degree Fahrenheit**.  
  - For mapping temperatures to Kalshi brackets, rely on the central utilities:  
    - `find_bracket_for_temp()`  
    - `determine_winning_bracket()`  
  - Do **not** duplicate or re-implement this mapping in ad-hoc code.

- **Historical vs â€œcurrentâ€ forecasts**  
  - Historical forecasts use `forecastBasisDate` and must respect â€œwhat was known whenâ€.  
  - â€œCurrentâ€ forecasts (for live trading) should use the non-`forecastBasisDate` endpoint.  
  - Keep these conceptually separated:
    - Historical: backtesting, performance studies.  
    - Current: live trading, near-term monitoring.  
  - If you see code mixing these, or using a historical endpoint to emulate a current one, treat it as **technical debt** and surface it in a plan.

- **No new live behavior without a plan**  
  - Donâ€™t casually change how orders are sent or how live forecasts are pulled.  
  - Any change that affects live trading must be covered by a `.claude/plans/active` plan and explicitly documented.

- **Information timing**  
  - Backtests must never see data that wouldnâ€™t have been available at that time.  
  - Examples:
    - Donâ€™t use same-day observed highs when simulating an open-time trade.  
    - When using historical VC forecasts, be explicit about `lead_days` / `lead_hours`.

---

### ğŸŸ£ 2.2 Refactor Planner

**Use when**: Youâ€™re restructuring code, splitting modules, or aligning the repo to the file dictionary, *without changing semantics*.

**Responsibilities:**

- Break up large modules (especially `open_maker/core.py` and `open_maker/utils.py`) into smaller, well-named modules that match `FILE_DICTIONARY_GUIDE.md`.  
- Keep the public surface area stable by using re-exports where appropriate (`__init__.py` pattern).  
- Clean up imports, type hints, small duplication, and dead code â€“ but do **not** change behavior unless a plan explicitly calls for it.

**Before a refactor, read:**

- `docs/permanent/FILE_DICTIONARY_GUIDE.md`  
- `docs/file_inventory.md` (or equivalent)  
- Any refactor plans like `docs/refactor_plan_v1.md`

**Refactor rules:**

- Always maintain **behavior parity** â€“ tests, CLI entry points, and public function signatures should behave the same.  
- After non-trivial refactors:
  - Run `pytest`.  
  - Run a representative backtest (e.g. a 30â€“90 day run for at least one city and strategy).  
- If youâ€™re unsure whether a function is domain-critical, consult the **Kalshi Weather Quant** persona and/or existing docs before moving it.

---

### ğŸŸ¢ 2.3 Dev Assistant

**Use when**: Doing general engineering work that isnâ€™t deeply tied to weather/Kalshi domain logic.

Examples:

- CI configuration, Makefiles, small helper scripts.  
- Documentation (markdown, docstrings, READMEs).  
- Utilities for logging, config, CLI argument parsing.  
- Plotting/backtest visualizations, report generation.

**Expectations:**

- Write clear, idiomatic Python 3.11+ with type hints.  
- Follow existing module naming and import patterns.  
- Add docstrings and comments explaining any non-obvious logic.  
- For domain-specific questions (forecast timing, bracket semantics, etc.), defer to the **Kalshi Weather Quant** persona and the domain docs.

---

## 3. Plan Management System

This project uses a `.claude/` directory to track medium-to-large tasks.

> **CRITICAL**: Always use THIS PROJECT'S `.claude/plans/` folder for all plans.
> - **USE**: `<project_root>/.claude/plans/`
> - **DO NOT USE**: `~/.claude/plans/` (home directory)
>
> When Claude Code prompts you to create a plan, write it to the project's `.claude/plans/active/` folder.
> Project plans must stay with the project for version control and context.
> See `.claude/plans/PLANS.md` for current active/completed plans and the plan lifecycle.

### 3.1 Directory Layout

```text
.claude/
  plans/
    active/          # Current work-in-progress plans
    completed/       # Finished plans (archived)
    templates/       # Plan templates
  agents/            # (Optional) persona-specific notes or shortcuts
  settings.local.json  # Local-only configuration, never committed
````

### 3.2 Before starting any multi-step task

1. **Check for active plans**

   ```bash
   ls .claude/plans/active/
   ```

2. If a relevant plan already exists:

   * Open it.
   * Read the **Context**, **Tasks**, and latest **Sign-off Log** entry.
   * Confirm the repo state matches the expectations in that log.

3. If no plan exists and the task spans more than ~30 minutes or multiple files:

   * Create a new plan in `.claude/plans/active/` using the template below.
   * Give it a descriptive `plan_id`.

### 3.3 Plan file template

Every plan should follow this structure:

```markdown
---
plan_id: descriptive-slug-name
created: YYYY-MM-DD
status: draft | in_progress | blocked | completed
priority: low | medium | high | critical
agent: kalshi-weather-quant | refactor-planner | dev-assistant
---

# Plan Title

## Objective
One sentence describing the goal.

## Context
Why this matters. Links to related docs/plans, relevant files, and any known constraints.

## Tasks
- [ ] Task 1
- [ ] Task 2
- [ ] Task 3

## Files to Create/Modify
| Action | Path | Notes |
|--------|------|-------|
| CREATE | `path/to/file.py` | Description |
| MODIFY | `path/to/existing.py` | What changes and why |

## Technical Details
Schemas, API patterns, code snippets, and any assumptions.  
Call out tricky parts (timezones, settlement edge cases, etc.).

## Completion Criteria
- [ ] All tasks checked
- [ ] Tests pass
- [ ] Backtest or smoke-test run
- [ ] Docs updated if necessary

## Sign-off Log

### YYYY-MM-DD HH:MM TZ
**Status**: In progress â€“ X% complete  
**Last completed**:
- âœ… Bullet list of what was done this session.

**Next steps**:
1. Immediate next action
2. Secondary action

**Blockers**: None / describe clearly

**Context for next session**:
Anything that would confuse â€œfuture youâ€ coming back cold.
```

### 3.4 Ending a session

Before you stop working:

1. Update the **Sign-off Log** in the active plan.
2. Mark any completed tasks with âœ….
3. Explicitly list the next 1â€“3 steps.
4. Note any blockers (tests failing, missing config, unclear API behavior, etc.).

### 3.5 Completing a plan

When a plan is done:

1. Set `status: completed` in the front matter.
2. Add a final Sign-off entry summarizing results.
3. Move the file to the archive:

   ```bash
   mv .claude/plans/active/plan-name.md .claude/plans/completed/YYYY-MM-DD_plan-name.md
   ```

---

## 4. Critical Project Rules

### 4.1 Datetime & Time Zone Handling

* Never use **naive** `datetime` objects in code that touches real data.

* Always be explicit:

  * `datetime_utc` â€“ TIMESTAMPTZ in UTC.
  * `datetime_local` â€“ local wall time in the cityâ€™s timezone.
  * `timezone` â€“ IANA timezone string (e.g. `America/Chicago`).
  * `tzoffset_minutes` â€“ offset from UTC in minutes for that timestamp.

* Weather day boundaries are defined in **local standard time** per NWS climate reports, *not* pure UTC.

* For forecasts and minute-level data:

  * Use VCâ€™s `datetimeEpoch` and `timezone`/`tzoffset` to compute both `datetime_utc` and `datetime_local`.
  * Store them both in the DB where appropriate.

### 4.2 Database Conventions

* Weather data lives under the `wx` schema.

  * This includes Visual Crossing tables (`wx.vc_*`), historical obs, forecasts, and settlement (`wx.settlement`).
* Kalshi data lives under the `kalshi` schema.
* Simulation/backtest outputs live under the `sim` schema.
* All schema changes must go through **Alembic** migrations.
* For â€œenum-likeâ€ text fields (e.g. `data_type`, `location_type`, `strike_type`), add a **CHECK constraint** enforcing allowed values.
* For ingestion pipelines, prefer idempotent **UPSERT patterns** with UNIQUE constraints so re-runs donâ€™t duplicate rows.

### 4.3 Visual Crossing API Patterns (high level)

* Use a **central elements builder** (e.g. `src/config/vc_elements.py`) to build the `elements` string â€“ do not hard-code element lists in multiple places.
* Station-locked queries use `stn:<station_id>` where station_id is typically an ICAO like `KMDW`, `KAUS`, `KDEN`, `KLAX`, `KMIA`, `KPHL` (see config).
* City-aggregate queries use human-readable strings like `"Chicago,IL"` or `"Austin,TX"` from config.
* Historical forecasts always include `forecastBasisDate` and should only be used in **backtesting / research** contexts.
* â€œCurrentâ€ forecasts for live trading should **not** use `forecastBasisDate`; they should use Timeline API in current/forecast mode.

Whenever you update ingestion:

* Double-check the **official Visual Crossing docs** for `include=`, `options=`, and limits.
* Be explicit about:

  * Granularity (5-minute obs, 15-minute forecast minutes).
  * Which mode youâ€™re in: obs vs current vs historical forecast.

### 4.4 Testing & Safety

* Always run **`pytest`** before committing behavioral changes.

* For any schema change:

  * Generate Alembic migration.
  * Run migrations on a test DB first.
  * Exercise at least one ingestion script and one backtest.

* For backtest or strategy changes:

  * Run a small backtest (e.g. one city, 30â€“90 days) for each affected strategy.
  * Compare high-level metrics (number of trades, total P&L, Sharpe) before and after if the change is meant to be â€œrefactor onlyâ€.

### 4.5 Live Trading Safety

* Default to **dry-run** unless explicitly told otherwise in the current plan.

* Before placing real orders:

  * Verify that forecasts being used are **non-zero and reasonable**.
  * Confirm that the **city and event date** match the Kalshi market in question.
  * Check that bet size is within a small, agreed-upon limit unless the plan explicitly changes it.

* Log all live decisions, including:

  * City, event date, and market/ticker.
  * Forecast inputs (basis date, lead days, predicted temp range).
  * Chosen bracket and entry price.
  * Any exit/override decisions and rationale.

---

## 5. Key File Locations

These may evolve, but in general:

| Purpose                  | Path / Notes                                       |
| ------------------------ | -------------------------------------------------- |
| Project docs             | `docs/permanent/`                                  |
| Planning notes           | `docs/planning_next_steps.md` and siblings         |
| File structure guide     | `docs/permanent/FILE_DICTIONARY_GUIDE.md`          |
| Datetime/API reference   | `docs/permanent/DATETIME_AND_API_REFERENCE.md`     |
| Ordinal model guide      | `docs/permanent/ORDINAL_CATBOOST_VALIDATION_GUIDE.md` |
| Database models          | `src/db/models.py`                                 |
| Visual Crossing client   | `src/weather/visual_crossing.py`                   |
| Kalshi client            | `src/kalshi/`                                      |
| Strategies               | `open_maker/`                                      |
| **ML Framework**         | `models/` (see Section 5.1 below)                  |
| **Analysis tools**       | `analysis/` (temperature rounding, research)       |
| Ingestion scripts        | `scripts/ingest_*`, `scripts/backfill_*`           |
| Training scripts         | `scripts/train_*.py`                               |
| Live trading scripts     | `scripts/live_*.py`                                |
| Config (cities, VC)      | `src/config/`                                      |
| Tuned parameters         | `config/live_trader_config.py`                     |
| Active plans             | `.claude/plans/active/`                            |
| Saved models             | `models/saved/*.json`                              |
| Legacy scripts           | `legacy/` (old VC ingestion, reference only)       |

If in doubt about where something should live, check `FILE_DICTIONARY_GUIDE.md` first.

### 5.1 ML Framework (`models/`)

The `models/` package implements the Î”-model framework for predicting temperature settlement deviations:

```text
models/
â”œâ”€â”€ __init__.py           # Package doc, version
â”œâ”€â”€ data/                 # Dataset building
â”‚   â”œâ”€â”€ loader.py         # Load raw data from DB
â”‚   â”œâ”€â”€ splits.py         # DayGroupedTimeSeriesSplit for CV
â”‚   â”œâ”€â”€ snapshot_builder.py  # Build training snapshots
â”‚   â””â”€â”€ tod_dataset_builder.py  # Time-of-day datasets
â”œâ”€â”€ features/             # Feature engineering (pure functions)
â”‚   â”œâ”€â”€ base.py           # FeatureSet, DELTA_CLASSES, compose_features
â”‚   â”œâ”€â”€ partial_day.py    # Stats from VC temps up to snapshot time
â”‚   â”œâ”€â”€ shape.py          # Plateau, spike, slope features
â”‚   â”œâ”€â”€ forecast.py       # T-1 forecast error features
â”‚   â”œâ”€â”€ calendar.py       # Day-of-week, month encoding
â”‚   â”œâ”€â”€ rules.py          # Rule-based meta-features
â”‚   â””â”€â”€ quality.py        # Data quality indicators
â”œâ”€â”€ training/             # Model trainers
â”‚   â”œâ”€â”€ base_trainer.py   # BaseTrainer ABC
â”‚   â”œâ”€â”€ logistic_trainer.py   # Logistic regression Î”-model
â”‚   â”œâ”€â”€ catboost_trainer.py   # CatBoost with Optuna tuning
â”‚   â””â”€â”€ ordinal_trainer.py    # Ordinal regression
â”œâ”€â”€ evaluation/           # Metrics and reports
â”‚   â”œâ”€â”€ metrics.py        # Accuracy, calibration, Brier
â”‚   â”œâ”€â”€ evaluator.py      # Cross-validation evaluator
â”‚   â””â”€â”€ reports.py        # Generate markdown reports
â”œâ”€â”€ inference/            # Live prediction
â”‚   â”œâ”€â”€ predictor.py      # DeltaPredictor class
â”‚   â”œâ”€â”€ probability.py    # Convert Î” to bracket probs
â”‚   â””â”€â”€ live_engine.py    # Real-time inference
â””â”€â”€ saved/                # Serialized models (JSON)
```

**Key concepts:**

- **Î” (delta) classes**: Buckets for settlement deviation from forecast (-2, -1, 0, +1, +2).
- **Features**: Computed identically for training (historical) and inference (live).
- **Time-of-day (TOD)**: Models that predict settlement from partial-day observations.
- **Ordinal regression**: Predicts probability distribution over Î” classes respecting order.

---

## 6. Code Style & Conventions

* Python **3.11+**, with type hints (`typing` / `collections.abc`).
* Use `dataclasses` where simple containers are needed.
* Prefer explicit imports (`from module import name`) over `import *`.
* Add docstrings to all public functions and classes; briefly explain *why*, not just *what*.
* Use the standard `logging` module instead of `print()`.
* Respect existing naming conventions:

  * `snake_case` for functions and vars.
  * `CamelCase` for classes.
  * Lowercase, hyphenated names for scripts (e.g. `ingest_vc_obs_backfill.py`).

---

## 7. Quick Reference Commands

### Development Setup

```bash
# Install production dependencies
make install
# or: pip install -e .

# Install dev dependencies (pytest, black, ruff, mypy)
make dev
# or: pip install -e ".[dev]"
```

### Database

```bash
# Start TimescaleDB container
make db-up

# Stop container
make db-down

# Reset database (destroy & recreate)
make db-reset

# Open psql shell
make db-shell

# Run Alembic migrations
make migrate
# or: alembic upgrade head

# Create new migration
alembic revision --autogenerate -m "describe-change"
```

### Testing & Code Quality

```bash
# Run all tests
make test
# or: pytest tests/ -v

# Run specific test file
pytest tests/test_something.py -v

# Lint code
make lint
# or: ruff check src/ scripts/ tests/

# Format code
make format
# or: black src/ scripts/ tests/

# Syntax-check a file
python3 -m py_compile src/path/to/file.py
```

### Ingestion

```bash
# Backfill Kalshi markets
make ingest-markets

# Backfill Kalshi candles
make ingest-candles

# Backfill VC observations
python scripts/ingest_vc_obs_backfill.py --city Chicago --start 2024-01-01 --end 2024-06-01

# Backfill VC historical forecasts
python scripts/ingest_vc_historical_forecast_parallel.py --city Chicago

# Ingest NWS settlements
python scripts/ingest_settlement_multi.py --city Chicago
```

### Training ML Models

```bash
# Train all cities (hourly snapshots)
python scripts/train_all_cities_hourly.py

# Train ordinal models
python scripts/train_all_cities_ordinal.py

# Train TOD v1 models
python scripts/train_tod_v1_all_cities.py

# Test inference on all cities
python scripts/test_inference_all_cities.py
```

### Backtesting

```bash
# Run backtest with base strategy
python -m open_maker.core --strategy open_maker_base --all-cities --days 180

# Run Optuna tuning
python -m open_maker.optuna_tuner --strategy open_maker_base --trials 100
```

### Live Trading (use with caution)

```bash
# WebSocket-based live trader
python scripts/live_ws_trader.py --dry-run

# Midnight heuristic trader
python scripts/live_midnight_trader.py --dry-run
```

### Utilities

```bash
# Check data freshness
python scripts/check_data_freshness.py

# Check data state
python scripts/check_data_state.py

# Regenerate file inventory
python tools/file_inventory.py
```

---

## 8. Full Directory Structure

```text
weather_updated/
â”œâ”€â”€ .claude/                 # Agent plans and settings
â”‚   â”œâ”€â”€ plans/
â”‚   â”‚   â”œâ”€â”€ active/          # In-progress plans
â”‚   â”‚   â”œâ”€â”€ completed/       # Archived plans
â”‚   â”‚   â”œâ”€â”€ templates/       # Plan templates
â”‚   â”‚   â””â”€â”€ PLANS.md         # Plan index and lifecycle
â”‚   â””â”€â”€ agents/              # Persona notes (optional)
â”œâ”€â”€ analysis/                # Research/analysis tools (NOT production)
â”‚   â””â”€â”€ temperature/         # Temperature rounding studies
â”œâ”€â”€ backtest/                # Midnight heuristic backtester
â”‚   â”œâ”€â”€ midnight_heuristic.py
â”‚   â””â”€â”€ optuna_tuning.py
â”œâ”€â”€ config/                  # Tuned parameters (JSON/Python)
â”‚   â””â”€â”€ live_trader_config.py
â”œâ”€â”€ docs/                    # Documentation
â”‚   â””â”€â”€ permanent/           # Stable reference docs
â”‚       â”œâ”€â”€ FILE_DICTIONARY_GUIDE.md
â”‚       â”œâ”€â”€ DATETIME_AND_API_REFERENCE.md
â”‚       â”œâ”€â”€ ORDINAL_CATBOOST_VALIDATION_GUIDE.md
â”‚       â”œâ”€â”€ QUERYING_VISUAL_CROSSING.md
â”‚       â””â”€â”€ how-tos/         # Step-by-step guides
â”œâ”€â”€ legacy/                  # Old scripts (reference only)
â”œâ”€â”€ migrations/              # Alembic migrations
â”‚   â””â”€â”€ versions/
â”œâ”€â”€ models/                  # ML framework (see Section 5.1)
â”‚   â”œâ”€â”€ data/                # Dataset building
â”‚   â”œâ”€â”€ features/            # Feature engineering
â”‚   â”œâ”€â”€ training/            # Model trainers
â”‚   â”œâ”€â”€ evaluation/          # Metrics and reports
â”‚   â”œâ”€â”€ inference/           # Live prediction
â”‚   â””â”€â”€ saved/               # Serialized models
â”œâ”€â”€ open_maker/              # Trading strategies
â”‚   â”œâ”€â”€ strategies/          # Strategy implementations
â”‚   â”œâ”€â”€ core.py              # Backtest engine
â”‚   â”œâ”€â”€ utils.py             # Bracket selection, fees
â”‚   â”œâ”€â”€ live_trader.py       # Live WS trader
â”‚   â”œâ”€â”€ manual_trade.py      # Manual CLI
â”‚   â”œâ”€â”€ optuna_tuner.py      # Parameter optimization
â”‚   â””â”€â”€ reporting.py         # Results reporting
â”œâ”€â”€ reports/                 # Generated reports
â”œâ”€â”€ scripts/                 # Ingestion, training, live trading
â”‚   â”œâ”€â”€ ingest_*.py          # Data ingestion
â”‚   â”œâ”€â”€ backfill_*.py        # Historical backfill
â”‚   â”œâ”€â”€ train_*.py           # Model training
â”‚   â”œâ”€â”€ live_*.py            # Live trading
â”‚   â””â”€â”€ check_*.py           # Data checks
â”œâ”€â”€ src/                     # Core infrastructure
â”‚   â”œâ”€â”€ config/              # Settings, cities, VC elements
â”‚   â”œâ”€â”€ db/                  # SQLAlchemy models, connection
â”‚   â”œâ”€â”€ ingest/              # Ingestion utilities
â”‚   â”œâ”€â”€ kalshi/              # Kalshi REST/WS client
â”‚   â”œâ”€â”€ trading/             # Fees, risk
â”‚   â”œâ”€â”€ utils/               # Rate limiting, retry
â”‚   â””â”€â”€ weather/             # Weather API clients (VC, NWS, IEM)
â”œâ”€â”€ systemd/                 # Systemd service files
â”œâ”€â”€ tests/                   # pytest tests
â”œâ”€â”€ tools/                   # Developer utilities
â”‚   â”œâ”€â”€ file_inventory.py
â”‚   â””â”€â”€ adhoc/               # One-off scripts
â”œâ”€â”€ CLAUDE.md                # This file
â”œâ”€â”€ README.md                # Project overview
â”œâ”€â”€ Makefile                 # Common commands
â”œâ”€â”€ pyproject.toml           # Package config
â”œâ”€â”€ alembic.ini              # Alembic config
â”œâ”€â”€ docker-compose.yml       # TimescaleDB setup
â””â”€â”€ requirements.txt         # Pip requirements
```

---

## 9. Keeping CLAUDE.md Up to Date

If you notice that this file is inaccurate or missing important context:

1. Note the issue and proposed change in the **Sign-off Log** of your current plan.
2. Draft the updated section of CLAUDE.md as part of that plan.
3. Once there is agreement (or you're confident it's correct and aligned with reality), update this file and mention the change in the plan's final sign-off.

**This file should always reflect how Claude Code is *actually* supposed to work in this repo, not wishful thinking.**

---

*Last updated: 2025-12-02*

