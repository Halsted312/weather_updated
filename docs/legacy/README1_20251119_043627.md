
---

## `docs/AGENT_DESIGN.md`

```markdown
# Weather Bracket Agent – Design & Implementation Guide

**Goal:** Trade and make markets in Kalshi “Highest temperature today” brackets by detecting **cross‑bracket acceleration** before the crowd, using order‑book pressure and 5‑minute station data to keep probabilities coherent and fees under control.

---

## 0) External Interfaces

### Kalshi WebSocket Market Data
- Subscribe to all brackets in the series (e.g., city = Chicago/Miami).
- The WS sends an **`orderbook_snapshot`** first, then **`orderbook_delta`** updates; use `market_tickers` to subscribe to many tickers in one stream.  
  _Reference:_ Kalshi WS docs (orderbook updates, snapshot→delta, multiple tickers). 

### Kalshi REST (reference & trading)
- “Get Market Orderbook” returns **YES bids and NO bids only**; asks are implied (YES ask = 100 − NO bid, etc.).  
  _Reference:_ Kalshi orderbook responses and REST orderbook docs.

### Visual Crossing (station‑exact, 5‑minute)
- Use Timeline API with `stn:<STATION_ID>` and `aggregateMinutes=5` for sub‑hourly granularity; VC normalizes/aggregates irregular station readings to a consistent 5–10‑minute grid (station‑dependent).  
  _Reference:_ VC Timeline API, sub‑hourly requests; VC real‑time/historical sub‑hourly update cadence.

---

## 1) Core Objects & Notation

Let brackets \(B_1,\ldots,B_K\) be disjoint temperature ranges (e.g., 81–82, 83–84, …).  
At time \(t\), define:
- **Market‑implied PMF** (from midprices): \(\hat{\mathbf{p}}^{\,mkt}_t = (p^{mkt}_{1,t},\dots,p^{mkt}_{K,t})\), roughly summing to 1 (cents ≈ probability).  
- **Weather PMF** (from MC nowcast of daily max): \(\hat{\mathbf{p}}^{\,wx}_t\).  
- **Running high** \(m_t = \max_{s\le t} T(s)\) from station obs (5‑min).  
- **Hazard** \(h_t = \Pr(\text{new high in next step} \mid \mathcal{F}_t)\).

We’ll maintain a **coherent** PMF \(\mathbf{p}_t\) via a **logistic‑normal** state and fuse market + weather. Logistic‑normal is the standard way to model **compositional** data (unit‑sum vectors) while allowing rich covariance.  

---

## 2) Feature Engineering

### 2.1 Kinematics across brackets (your acceleration idea)
For each bracket \(i\):
- Mid \(p_i(t)\) (micro‑VWAP over last few seconds or NBBO midpoint).
- Velocity \(v_i(t)\): EWMA difference; Acceleration \(a_i(t)\): EWMA difference of velocity.
- **Relative acceleration** to neighbors: \(a_i-a_{i\pm1}\).
- **Center of mass** of PMF: \(\mu_t=\sum_i b_i p_i(t)\) with \(b_i\)=bin midpoint; and \(\dot\mu_t,\ddot\mu_t\) to detect whole‑distribution migration.

### 2.2 Microstructure pressure
- **OFI** (order‑flow imbalance) over short windows: linear driver of short‑horizon price moves; slope inversely proportional to depth.  
- **Queue imbalance** at the best: \(QI = \frac{bid\_qty}{bid\_qty+ask\_qty}\).
- **Hawkes intensity** \(\hat\lambda_i(t)\) for aggressive trades: flags bursts / self‑excitation.

### 2.3 Weather / Time
- Distance from running high to each bin: \(d_i(t)=b_i - m_t\).
- Monte‑Carlo nowcast PMF & **hazard** from station+forecast on a 5‑minute grid.

---

## 3) Models

### 3.1 Coherent probability tracker (logistic‑normal state filter)
We treat the PMF \(\mathbf{p}_t\) as a composition and work in **logit space**:
\[
\mathbf{z}_t = \text{logit}\!\left(\frac{\mathbf{p}_t}{1^\top \mathbf{p}_t}\right),\quad \mathbf{p}_t = \text{softmax}(\mathbf{z}_t).
\]
**State:** \(\mathbf{z}_t = \mathbf{z}_{t-\Delta} + \mathbf{w}_t,\ \mathbf{w}_t\sim\mathcal{N}(0,Q)\).  
**Measurements:**
- Market: noisy read of \(\mathbf{p}_t\) from midprices (variance expands when depth/volume are low).
- Weather: \(\hat{\mathbf{p}}^{\,wx}_t\) from MC as an additional, lower‑variance observation (or do an **opinion pool** in logit space).

Implement with a small **UKF/EKF** or a lightweight **particle filter** if you prefer to track just \(\mu_t,\sigma_t\) and reconstruct \(\mathbf{p}_t\) from a parametric family (e.g., discretized skew‑normal).

### 3.2 Short‑horizon move forecaster (seconds→minutes)
Goal: predict sign/size of \(\Delta p_i(t+\delta)\) for \(\delta \in [5,60]\) seconds using:
- \(v_i,a_i\), neighbor diffs \((a_i-a_{i\pm1})\),
- OFI/QI, last‑trade run metrics,
- Hawkes intensities,
- weather features \([d_i,\ h_t]\),
- regime flags (change‑point).

Start with **regularized logistic / ridge**; upgrade to an online GBM once features are stable.

### 3.3 Regime / change‑point detector
Run **CUSUM/FO‑CuS** over \(\mu_t\) and the first PC(s) of \(\mathbf{p}_t\). On detection, (i) widen process noise in the filter, (ii) allow taker if predicted move > fee+slippage.

---

## 4) Signals

**Leader–follower (bin‑level):**  
If \(a_j>0\), neighbors decelerate, OFI\(_j\)>0, and \(\dot\mu_t>0\), **buy \(j\)** (maker); if hazard is high and Hawkes spikes, allow **taker**.

**Migration (PMF‑level):**  
If \(\ddot\mu_t>0\) with confidence, reduce lower‑bin longs, add \(j{+}1\) exposure (maker first).

**Gates:** liquidity floor; PMF coherence; fee‑clearance; time‑of‑day (hazard).

---

## 5) Execution & Fees

**Maker first.** Compute net EV for maker vs taker:
\[
\text{EV}_{maker} \approx P(\text{fill in }T)(\mathbb{E}[p_{t+\delta}]-p_{limit}) - \text{fee}_{maker};\quad
\text{EV}_{taker} \approx \mathbb{E}[p_{t+\delta}]-p_{ask/bid} - \text{fee}_{taker}.
\]
Kalshi fees scale with \(0.07 \cdot p(1-p)\) for takers and \(0.0175 \cdot p(1-p)\) for makers (rounded up to cent). Encode this exactly; it’s crucial for thresholding.  

---

## 6) Calibration

We post‑hoc calibrate predicted bracket probabilities and short‑horizon move scores.

- **Platt scaling** (sigmoid): great with limited calibration data, sigmoid‑shaped miscalibration.  
- **Isotonic regression**: non‑parametric monotone map; powerful but overfits when data are scarce.  
- **Beta calibration**: parametric map on \([0,1]\); often better than logistic when inputs are probabilities.  
- **Temperature scaling**: one‑parameter logit divider; simple and effective baseline.

Use **cross‑validated** calibration (e.g., `CalibratedClassifierCV`) and monitor **ECE** / **Brier**. Keep per‑city calibrators; retrain monthly or when drift detected.  

---

## 7) Backtesting & Shadow

- **Replay** L2 (or minute candles if L2 missing), VC 5‑min temps; run the **same** filter/signals.  
- **Maker fills:** heuristic fill model from queue stats; **taker fills:** immediate.  
- Metrics: net P&L **after fees**, Brier/ECE for PMF, hit‑rate for \(\Delta p\), max DD, turnover.  
- **Shadow mode**: in live markets, log intended orders and hypothetical fills; promote only after stable P&L.

---

## 8) Risk

- Daily loss cap, per‑bracket and per‑city exposure limits.  
- “Hazard throttle” (reduce leverage when hazard low).  
- Cancel‑on‑disconnect; snapshot recovery on WS reconnect.

---

## 9) Extending beyond Chicago

- Use `CITY` and `STATION_ID` config list; spin one filter per city.  
- Station mapping must match the settlement station for each Kalshi series.

---

## 10) Deliverables to build

- WS ingest, VC ingest, feature stream, logistic‑normal filter, MC nowcast, calibration, signal engine, execution, backtester, dual‑mode switch, docker‑compose.

```

**Citations for AGENT_DESIGN.md**

* Kalshi WS snapshot→delta; multi‑ticker subscribe. ([Kalshi API Documentation][1])
* Kalshi orderbook asks implied by YES/NO reciprocity. ([Kalshi API Documentation][2])
* VC Timeline API & sub‑hourly (5–10 min) request guidance; station cadence. ([Visual Crossing][3])
* Logistic‑normal for compositions (Aitchison & Shen; Aitchison book). ([OUP Academic][4])
* OFI drives short‑term price changes (linear, inverse to depth). ([arXiv][5])
* Hawkes processes for high‑freq market bursts. ([arXiv][6])
* Fee formulas and maker/taker structure. ([Kalshi][7])
* Calibration: scikit‑learn docs; Platt; isotonic; Beta; temperature scaling. ([Scikit-learn][8])

---

## `README.md`

```markdown
# Weather Bracket Agent

Trade and make markets on Kalshi “Highest temperature today” brackets using live L2 microstructure + 5‑minute station weather.

## TL;DR
- **Maker first**, fee‑aware taker switches
- **Coherent bracket PMF** via logistic‑normal filtering
- **Acceleration arb**: lead/lag across brackets
- **Monte‑Carlo** Tmax nowcast + hazard
- **Dual mode**: `TRADE_MODE=live|paper`
- **Backtester** with fee modeling

## Quick Start
1. **Config** (`.env`):
```

CITY=chicago
STATION_ID=KMDW
VC_API_KEY=...
KALSHI_API_KEY=...
TRADE_MODE=paper       # live|paper
DB_URL=postgres://user:pass@postgres:5432/kalshi

````
2. **Docker**:
```bash
docker compose up --build
````

Services:

* `kalshi_ws` – WebSocket L2 → DB
* `vc_ingest` – Visual Crossing 5‑min station obs/forecast → DB
* `signals`   – logistic‑normal filter + features + calibration
* `exec`      – maker/taker orders (no orders in paper mode)
* `backtest`  – on demand (not started by default)
* `postgres`  – storage

3. **Paper trade first**. Flip to `TRADE_MODE=live` only after backtests + shadow are green.

## Directory

```
agent/
  config.py
  data/
    kalshi_ws.py
    visualcrossing.py
  features/
    kinematics.py
    ofi.py
    hawkes.py
  models/
    pmf_filter.py
    monte_carlo.py
    calibration.py
    change_point.py
  signals/
    accel_signal.py
  execution/
    engine.py
    fees.py
  backtest/
    replay.py
    fillsim.py
  main.py
docker-compose.yml
docs/AGENT_DESIGN.md
```

## Notes

* The orderbook returns YES bids & NO bids; derive asks as complements.
* Visual Crossing sub‑hourly: use `aggregateMinutes=5` and `stn:<ID>` to lock to the settlement station.
* Calibrate probabilities monthly (Platt/Isotonic/Beta). Track ECE and Brier.

````

**Citations for README**  
- Kalshi orderbook semantics. :contentReference[oaicite:8]{index=8}  
- VC sub‑hourly and station lock. :contentReference[oaicite:9]{index=9}

---

## Code stubs (Python)

> These are **production‑style** stubs with types and docstrings, ready for your agent to flesh out. They assume your existing VC ingestion code works; swap it into `visualcrossing.py`.

### `agent/config.py`
```python
from __future__ import annotations
import os
from dataclasses import dataclass

@dataclass(frozen=True)
class Config:
    city: str = os.getenv("CITY", "chicago")
    station_id: str = os.getenv("STATION_ID", "KMDW")
    trade_mode: str = os.getenv("TRADE_MODE", "paper")  # 'paper' or 'live'
    db_url: str = os.getenv("DB_URL", "postgres://user:pass@postgres:5432/kalshi")
    vc_api_key: str = os.getenv("VC_API_KEY", "")
    kalshi_key: str = os.getenv("KALSHI_API_KEY", "")
    ws_url: str = "wss://api.elections.kalshi.com/trade-api/ws/v2"
    mc_paths: int = int(os.getenv("MC_PATHS", "4000"))
    mc_step_minutes: int = 5
    delta_seconds: int = int(os.getenv("DELTA_SECONDS", "20"))  # forecast horizon for microstructure
    maker_thresh_cents: float = float(os.getenv("MAKER_THRESH_CENTS", "1.5"))
    taker_thresh_cents: float = float(os.getenv("TAKER_THRESH_CENTS", "3.0"))
    max_daily_loss: float = float(os.getenv("MAX_DAILY_LOSS", "300.0"))
    log_level: str = os.getenv("LOG_LEVEL", "INFO")
````

### `agent/data/kalshi_ws.py`

```python
import asyncio, json, logging
import websockets
from typing import Dict, Any, List, Tuple, Optional
from agent.config import Config

log = logging.getLogger(__name__)

class OrderBook:
    """Minimal in-memory L2 with snapshot→delta application."""
    def __init__(self):
        self.seq = 0
        self.yes_bids: List[Tuple[int, int]] = []  # (price_cents, qty)
        self.no_bids:  List[Tuple[int, int]] = []
        self.best_yes_bid = 0
        self.best_no_bid  = 0

    def apply_snapshot(self, snap: Dict[str, Any]):
        self.seq = snap["seq"]
        self.yes_bids = [(int(p), int(q)) for p, q in snap["orderbook"]["yes"]]
        self.no_bids  = [(int(p), int(q)) for p, q in snap["orderbook"]["no"]]
        self._refresh_top()

    def apply_delta(self, delta: Dict[str, Any]):
        if delta["seq"] <= self.seq:
            return
        self.seq = delta["seq"]
        # apply yes/no add/remove/update deltas (omitted for brevity)
        self._refresh_top()

    def _refresh_top(self):
        self.best_yes_bid = self.yes_bids[0][0] if self.yes_bids else 0
        self.best_no_bid  = self.no_bids[0][0]  if self.no_bids else 0

    def mid_yes(self) -> float:
        # YES ask is implied by NO bid
        ask = 100 - self.best_no_bid if self.best_no_bid else None
        bid = self.best_yes_bid if self.best_yes_bid else None
        if ask is None and bid is None:
            return 0.0
        if ask is None:
            return bid / 100.0
        if bid is None:
            return ask / 100.0
        return 0.5 * (ask + bid) / 100.0

class KalshiWS:
    def __init__(self, cfg: Config):
        self.cfg = cfg
        self.books: Dict[str, OrderBook] = {}

    async def run(self, tickers: List[str]):
        headers = [("KALSHI-ACCESS-KEY", self.cfg.kalshi_key)]
        async with websockets.connect(self.cfg.ws_url, extra_headers=headers, max_size=2**23) as ws:
            sub = {"id":1,"cmd":"subscribe","params":{"channels":["orderbook_delta"],"market_tickers":tickers}}
            await ws.send(json.dumps(sub))
            async for raw in ws:
                msg = json.loads(raw)
                typ = msg.get("type")
                tkr = msg.get("market_ticker")
                if typ == "orderbook_snapshot":
                    self.books.setdefault(tkr, OrderBook()).apply_snapshot(msg)
                elif typ == "orderbook_delta":
                    self.books.setdefault(tkr, OrderBook()).apply_delta(msg)
                # persist to DB / publish to feature bus here
```

*Why only bids?* Kalshi returns YES & NO bids; asks are implied by reciprocity (YES ask = 100 − NO bid). ([Kalshi API Documentation][2])

### `agent/data/visualcrossing.py`

```python
import httpx, datetime as dt
from typing import Dict, Any, List
from agent.config import Config

BASE = "https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline"

def fetch_station_today(cfg: Config) -> Dict[str, Any]:
    """Station-locked, 5-minute aggregation; include obs + forecast."""
    params = {
        "unitGroup": "us",
        "include": "obs,fcst",
        "elements": "datetime,temp,dew,humidity,windspeed,conditions",
        "aggregateMinutes": "5",
        "combinationMethod": "best",
        "maxStations": "1",
        "key": cfg.vc_api_key,
        "contentType": "json",
    }
    url = f"{BASE}/stn:{cfg.station_id}/today"
    r = httpx.get(url, params=params, timeout=15)
    r.raise_for_status()
    return r.json()
```

*VC supports sub‑hourly via `aggregateMinutes=5` and normalizes irregular minute obs; smallest interval 5–10 min by station.* ([Visual Crossing][9])

### `agent/features/kinematics.py`

```python
import numpy as np
from collections import deque
from typing import Dict, Deque, Tuple

class Kinematics:
    """Compute mid/velocity/acceleration per bracket with robust EWM diffs."""
    def __init__(self, window:int=30, alpha:float=0.4):
        self.window = window
        self.alpha = alpha
        self.hist: Dict[str, Deque[float]] = {}

    def update(self, tkr:str, mid:float) -> Tuple[float,float,float]:
        q = self.hist.setdefault(tkr, deque(maxlen=self.window))
        q.append(mid)
        if len(q) < 4: return mid, 0.0, 0.0
        x = np.asarray(q, dtype=float)
        v = np.diff(x)                    # per tick
        # EWMA smoothing
        w = (1 - self.alpha) ** np.arange(len(v)-1, -1, -1)
        v_ewm = (w * v).sum() / w.sum()
        a = np.diff(v)
        if len(a) == 0: return mid, v_ewm, 0.0
        w2 = (1 - self.alpha) ** np.arange(len(a)-1, -1, -1)
        a_ewm = (w2 * a).sum() / w2.sum()
        return mid, float(v_ewm), float(a_ewm)
```

### `agent/features/ofi.py`

```python
from typing import List, Tuple

def ofi(best_bid_before:int, best_bid_after:int,
        best_ask_before:int, best_ask_after:int,
        bid_vol_change:int, ask_vol_change:int) -> int:
    """
    Cont-Kukanov-Stoikov OFI at the best levels (simplified):
    +1 for events increasing demand at bid or decreasing supply at ask,
    -1 for the opposite; accumulate with volume at best.
    """
    # This is a simplified placeholder; production version should track
    # queue insertions/deletions and aggressive hits/lifts explicitly.
    term_bid = (best_bid_after - best_bid_before) + bid_vol_change
    term_ask = (best_ask_before - best_ask_after) + ask_vol_change
    return int(term_bid + term_ask)
```

*Order‑flow imbalance at best levels linearly relates to short‑horizon price change; slope ~ inverse depth.* ([arXiv][5])

### `agent/features/hawkes.py`

```python
import numpy as np

class OneDimHawkes:
    """Tiny exponential-kernel Hawkes intensity estimator for buy/sell streams."""
    def __init__(self, baseline:float=0.1, alpha:float=0.5, beta:float=2.0):
        self.mu = baseline; self.alpha = alpha; self.beta = beta
        self.last_t = None; self.intensity = baseline

    def on_event(self, t:float):
        if self.last_t is None:
            self.intensity = self.mu + self.alpha
        else:
            decay = np.exp(-self.beta * (t - self.last_t))
            self.intensity = self.mu + self.intensity * decay + self.alpha
        self.last_t = t
        return self.intensity
```

*Hawkes processes capture self‑excitation/bursts common in LOB event streams.* ([arXiv][6])

### `agent/models/monte_carlo.py`

```python
import numpy as np
from typing import Dict, Any, Tuple

def mc_tmax_pmf(obs_series, fcst_series, bins, N=4000, rho=0.8, sigmas=None):
    """
    Simulate rest-of-day 5-min temps: T = F + AR(1) residual.
    Return bracket PMF and hazard of a new high in next step.
    """
    # Build baseline path F and estimate residual sigma by lead time (stub).
    F = np.asarray(fcst_series, dtype=float)
    K = len(F); sig = np.ones(K)* (0.6 if sigmas is None else 0.6)
    eps = np.zeros((N, K))
    for k in range(K):
        if k==0: eps[:,k] = np.random.normal(0, sig[k], N)
        else:    eps[:,k] = rho*eps[:,k-1] + np.sqrt(1-rho**2)*np.random.normal(0, sig[k], N)
    T = F + eps
    # Running high so far:
    m_run = float(np.max([x for _, x in obs_series]))
    M_future = T.max(1)
    M = np.maximum(m_run, M_future)
    # PMF over bins:
    pmf = [np.mean((M >= lo) & (M <= hi)) for (lo, hi) in bins]
    # Hazard ~ fraction that first exceed m_run next step:
    # (Placeholder: compute properly with first-passage check.)
    hazard = float(np.mean(T[:,0] > m_run))
    return pmf, hazard
```

### `agent/models/pmf_filter.py`

```python
import numpy as np
from typing import Dict, List

def softmax(z: np.ndarray) -> np.ndarray:
    ez = np.exp(z - np.max(z))
    return ez / ez.sum()

class LogisticNormalFilter:
    """UKF-lite over softmax(logits) to keep bracket PMF coherent."""
    def __init__(self, K:int, q_var:float=1e-4, r_mkt:float=2e-3, r_wx:float=1e-3):
        self.K = K
        self.z = np.zeros(K)            # logits
        self.Q = np.eye(K)*q_var
        self.Rm = np.eye(K)*r_mkt       # market obs noise
        self.Rw = np.eye(K)*r_wx        # weather obs noise

    def step(self, p_mkt: np.ndarray, p_wx: np.ndarray, w_mkt: float, w_wx: float) -> np.ndarray:
        # Predict
        self.z = self.z                  # random walk; Q could be added here
        # Update with market (log-space residual)
        pm = p_mkt / max(p_mkt.sum(), 1e-9)
        pw = p_wx  / max(p_wx.sum(),  1e-9)
        # Simple linearized blend in logit space as a placeholder for UKF:
        zm = np.log(np.maximum(pm,1e-9))  # log-prob ~ proxy for logits
        zw = np.log(np.maximum(pw,1e-9))
        self.z = (w_mkt*zm + w_wx*zw + self.z) / (w_mkt + w_wx + 1e-9)
        p = softmax(self.z)
        return p
```

*Why logistic‑normal?* It’s a principled way to model vectors of probabilities (compositions) and filter them with Gaussian tools. ([OUP Academic][4])

### `agent/models/calibration.py`

```python
from typing import Literal, Tuple
import numpy as np

try:
    from sklearn.calibration import CalibratedClassifierCV
    from sklearn.isotonic import IsotonicRegression
    from sklearn.linear_model import LogisticRegression
except Exception:
    CalibratedClassifierCV = None

Method = Literal["platt","isotonic","beta","temperature"]

class Calibrator:
    """Wraps Platt (logistic), Isotonic, Beta (stub), Temperature scaling (stub)."""
    def __init__(self, method: Method = "platt"):
        self.method = method
        self.model = None
        self.T = 1.0  # temperature

    def fit(self, scores: np.ndarray, labels: np.ndarray):
        if self.method == "platt":
            lr = LogisticRegression(max_iter=1000)
            self.model = lr.fit(scores.reshape(-1,1), labels)
        elif self.method == "isotonic":
            ir = IsotonicRegression(out_of_bounds="clip")
            self.model = ir.fit(scores, labels)
        elif self.method == "temperature":
            # minimize NLL over T (one parameter)
            self.T = self._fit_temperature(scores, labels)
        elif self.method == "beta":
            # placeholder: implement Kull et al. (2017) parametric map on [0,1]
            # p' = BetaCal(p ; a,b,c)
            raise NotImplementedError("Beta calibration not yet implemented")
        else:
            raise ValueError(self.method)

    def predict(self, scores: np.ndarray) -> np.ndarray:
        if self.method == "platt":
            return self.model.predict_proba(scores.reshape(-1,1))[:,1]
        elif self.method == "isotonic":
            return self.model.predict(scores)
        elif self.method == "temperature":
            return 1.0 / (1.0 + np.exp(-scores / max(self.T,1e-6)))
        elif self.method == "beta":
            raise NotImplementedError
        return scores

    def _fit_temperature(self, scores: np.ndarray, labels: np.ndarray) -> float:
        # crude 1D search over T to minimize NLL
        Ts = np.linspace(0.5, 5.0, 30)
        best_T, best_nll = 1.0, 1e9
        for T in Ts:
            p = 1.0/(1.0+np.exp(-scores/T))
            eps=1e-12; nll = -np.mean(labels*np.log(p+eps)+(1-labels)*np.log(1-p+eps))
            if nll < best_nll: best_T, best_nll = T, nll
        return best_T
```

*Calibration background: scikit‑learn’s module; Platt scaling; isotonic; beta calibration; temperature scaling.* ([Scikit-learn][8])

### `agent/models/change_point.py`

```python
import numpy as np

class CUSUM:
    """Online mean-shift detector over a univariate series (e.g., mu_t)."""
    def __init__(self, k=0.005, h=0.03):
        self.k = k; self.h = h
        self.gp = 0.0; self.gn = 0.0

    def update(self, x: float) -> bool:
        self.gp = max(0.0, self.gp + x - self.k)
        self.gn = max(0.0, self.gn - x - self.k)
        return (self.gp > self.h) or (self.gn > self.h)
```

*CUSUM (and FO‑CuS variants) provide simple, robust online change detection.* ([Scikit-learn][10])

### `agent/signals/accel_signal.py`

```python
from typing import Dict, List

def accel_arbitrage(pmf, mids, vel, acc, ofi, qi, hazard, neighbors, fees, taker_allowed=False):
    """
    Generate bracket-level intents:
    - Long bins with positive accel that dominate neighbors
    - Hedge via neighbor shorts if needed
    - Gate with OFI>0, QI>0.5, liquidity, and hazard
    """
    intents: List[Dict] = []
    K = len(mids)
    for j in range(1, K-1):
        lead = acc[j] - max(acc[j-1], acc[j+1])
        if lead > 0 and vel[j] > 0 and ofi[j] > 0 and qi[j] > 0.5 and hazard > 0.1:
            intents.append({"tkr": neighbors[j]["ticker"],
                            "side": "BUY",
                            "style": "maker" if not taker_allowed else "maker_or_taker",
                            "edge_hint": lead})
    return intents
```

### `agent/execution/fees.py`

```python
def taker_fee_cents(price_cents:int, contracts:int)->int:
    # fees = round_up(0.07 * C * P * (1-P)), P in dollars
    P = price_cents / 100.0
    fee = 0.07 * contracts * P * (1 - P)
    return int(fee*100 + 0.999)  # cents, rounded up

def maker_fee_cents(price_cents:int, contracts:int)->int:
    # fees = round_up(0.0175 * C * P * (1-P))
    P = price_cents / 100.0
    fee = 0.0175 * contracts * P * (1 - P)
    return int(fee*100 + 0.999)
```

*Fee formulas per Kalshi fee schedule (maker vs taker).* ([Kalshi][7])

### `agent/execution/engine.py`

```python
from typing import Dict, List
from agent.execution.fees import taker_fee_cents, maker_fee_cents

def choose_execution(mid_now:float, mid_pred:float, depth:int, style:str,
                     price_cents:int, contracts:int, maker_thresh:float, taker_thresh:float)->Dict:
    """Return an order spec or None based on fee-aware expected edge."""
    exp_move_cents = int(round((mid_pred - mid_now)*100))
    if style.startswith("maker"):
        if abs(exp_move_cents) >= maker_thresh:
            fee = maker_fee_cents(price_cents, contracts)
            return {"type":"limit","side":"buy" if exp_move_cents>0 else "sell",
                    "price_cents": price_cents, "qty": contracts, "fee_cents":fee}
    if "taker" in style:
        if abs(exp_move_cents) >= taker_thresh:
            fee = taker_fee_cents(price_cents, contracts)
            return {"type":"market","side":"buy" if exp_move_cents>0 else "sell",
                    "qty": contracts, "fee_cents":fee}
    return {}
```

### `agent/backtest/replay.py`

```python
class Replayer:
    """
    Replays L2 deltas + 5-min weather to produce P&L:
    - same filter/signals/execution policy
    - maker fill model based on queue times at your posted price
    - taker fills immediate
    """
    ...
```

### `agent/main.py`

```python
import asyncio, logging
from agent.config import Config
from agent.data.kalshi_ws import KalshiWS
from agent.data.visualcrossing import fetch_station_today

async def main():
    cfg = Config()
    logging.basicConfig(level=cfg.log_level)
    # 1) spin WS and VC loops (omitted details)
    # 2) build feature stream → pmf filter → signals → execution
    # 3) honor TRADE_MODE for live vs paper

if __name__ == "__main__":
    asyncio.run(main())
```

### `docker-compose.yml` (skeletal)

```yaml
version: "3.9"
services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: kalshi
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    ports: ["5432:5432"]
    volumes: ["pgdata:/var/lib/postgresql/data"]

  kalshi_ws:
    build: .
    command: python -m agent.data.kalshi_ws
    environment: [DB_URL=${DB_URL}, KALSHI_API_KEY=${KALSHI_API_KEY}]
    depends_on: [postgres]

  vc_ingest:
    build: .
    command: python -m agent.data.visualcrossing
    environment: [DB_URL=${DB_URL}, VC_API_KEY=${VC_API_KEY}, STATION_ID=${STATION_ID}]
    depends_on: [postgres]

  signals:
    build: .
    command: python -m agent.main
    environment:
      - DB_URL=${DB_URL}
      - TRADE_MODE=${TRADE_MODE}
    depends_on: [kalshi_ws, vc_ingest]

volumes:
  pgdata:
```

---

## How this answers your “curve‑fit vs Monte‑Carlo” question

* **Curve‑fit (exponential/poly/sine) on a single bracket** captures *local* momentum but **ignores mass conservation** and neighbor constraints; you risk false accelerations in low volume.
* **Our design** uses:

  * PMF‑level filter (logistic‑normal) → probabilities across bins **sum to ~1** and move coherently,
  * Microstructure pressure (OFI, Hawkes) to decide **which bracket leads** *now*,
  * **Monte‑Carlo nowcast** & **hazard** to know **when** moves are likely to stick (diurnal + station reality),
  * **Calibration** so your probabilities and EV are reliable after fees.

This combination is what lets you **front‑run** the bin that will reprice, *and* do it maker‑first most of the time.

---

### Key external references used above

* **Kalshi WebSocket / Market Data / Orderbook semantics:** snapshot→delta; asks implied from YES/NO bids. ([Kalshi API Documentation][1])
* **Visual Crossing:** Timeline API; sub‑hourly (5–10 min) with `aggregateMinutes=5`; station cadence and normalization. ([Visual Crossing][3])
* **OFI and short‑term price impact:** linear relation; inverse with depth. ([arXiv][5])
* **Hawkes in finance:** review of applications to LOB events. ([arXiv][6])
* **Logistic‑normal for compositional PMFs:** Aitchison & Shen; Aitchison book. ([OUP Academic][4])
* **Fee math:** maker vs taker formulas (round‑up). ([Kalshi][7])
* **Calibration:** scikit‑learn calibration, Platt, isotonic; Beta calibration & temperature scaling. ([Scikit-learn][8])

---

## What to ask your agent to do next (cut‑and‑ship tasks)

1. **Wire WS + VC** to DB and a lightweight in‑proc “feature bus.”
2. Implement **OFI** properly from L2 deltas + trade prints; add **QI** and **Hawkes**.
3. Finish the **logistic‑normal UKF** (replace the linearized blend stub).
4. Implement **MC nowcast** hazard with first‑passage logic.
5. Finish **execution**: order placement/cancel and fee‑aware maker/taker toggle; add daily kill‑switch.
6. Build the **backtester** and **shadow mode**.
7. Add **calibration** training scripts; ship with Platt & Isotonic first; add Beta later.

If you want I can also tailor the ticker discovery for Chicago/Miami series and produce SQL schemas and ETL scripts; the scaffolding above is designed to drop straight into your `kalshi_weather` stack and reuse your Visual Crossing calls.

[1]: https://docs.kalshi.com/websockets/orderbook-updates?utm_source=chatgpt.com "Orderbook Updates - API Documentation"
[2]: https://docs.kalshi.com/getting_started/orderbook_responses?utm_source=chatgpt.com "Orderbook Responses - API Documentation"
[3]: https://www.visualcrossing.com/resources/documentation/weather-api/timeline-weather-api/?utm_source=chatgpt.com "Weather API Documentation"
[4]: https://academic.oup.com/jrsssb/article/44/2/139/7027742?utm_source=chatgpt.com "Statistical Analysis of Compositional Data - Oxford Academic"
[5]: https://arxiv.org/abs/1011.6402?utm_source=chatgpt.com "The Price Impact of Order Book Events"
[6]: https://arxiv.org/abs/1502.04592?utm_source=chatgpt.com "Hawkes processes in finance"
[7]: https://kalshi.com/docs/kalshi-fee-schedule.pdf?utm_source=chatgpt.com "Fee Schedule for Oct 2025"
[8]: https://scikit-learn.org/stable/modules/calibration.html?utm_source=chatgpt.com "1.16. Probability calibration"
[9]: https://www.visualcrossing.com/resources/documentation/weather-api/sub-hourly-data-in-the-timeline-weather-api-2/?utm_source=chatgpt.com "Requesting sub-hourly data in the Timeline Weather API"
[10]: https://scikit-learn.org/stable/modules/isotonic.html?utm_source=chatgpt.com "1.15. Isotonic regression"
