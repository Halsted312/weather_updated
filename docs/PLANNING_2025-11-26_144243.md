# Kalshi Weather Trading Pipeline - Planning & Continuation Document

**Created:** 2025-11-26 14:42:43 UTC
**Last Updated:** 2025-11-26 14:42:43 UTC
**Status:** Ready for backfill and Option 2 implementation

---

## 1. Current State Summary

### 1.1 Database Infrastructure (COMPLETE)

| Component | Status | Notes |
|-----------|--------|-------|
| PostgreSQL + TimescaleDB | ✅ Running | Docker container `kalshi_weather_db` on port 5434 |
| Schema `kalshi` | ✅ Created | markets, candles_1m (hypertable) |
| Schema `wx` | ✅ Created | minute_obs (hypertable), settlement |
| Schema `sim` | ❌ Pending | Not yet created |
| Schema `feature` | ❌ Pending | For Option 2 views |

### 1.2 Data State (as of 2025-11-26)

#### Kalshi Markets
| City | Markets | Days | Date Range |
|------|---------|------|------------|
| Chicago | 42 | 7 | 2025-11-19 to 2025-11-25 |
| Austin | 0 | 0 | - |
| Denver | 0 | 0 | - |
| Los Angeles | 0 | 0 | - |
| Miami | 0 | 0 | - |
| Philadelphia | 0 | 0 | - |

#### Kalshi Candles (1-minute)
| City | Source | Count | Date Range |
|------|--------|-------|------------|
| Chicago | api_event | 16,052 | 2025-11-20 to 2025-11-24 |
| Chicago | trades | 5,025 | 2025-11-18 to 2025-11-26 |
| Others | - | 0 | - |

**Total candles:** 21,077

#### Weather Observations (5-minute Visual Crossing)
| Station | City | Observations | Days | Date Range |
|---------|------|--------------|------|------------|
| KMDW | Chicago | 288 | 1 | 2025-11-25 |
| KAUS | Austin | 0 | 0 | - |
| KDEN | Denver | 0 | 0 | - |
| KLAX | Los Angeles | 0 | 0 | - |
| KMIA | Miami | 0 | 0 | - |
| KPHL | Philadelphia | 0 | 0 | - |

#### Settlement Data (NWS Official Tmax)
| City | Days | Date Range |
|------|------|------------|
| Chicago | 1 | 2025-11-25 |
| Others | 0 | - |

---

## 2. What's Complete

### 2.1 Core Infrastructure
- [x] PostgreSQL + TimescaleDB Docker setup
- [x] SQLAlchemy ORM models (`src/db/models.py`)
- [x] Database connection helpers (`src/db/__init__.py`)
- [x] Schema creation for `kalshi` and `wx`

### 2.2 Kalshi Client & Schemas
- [x] `src/kalshi/client.py` - Full API client with:
  - JWT authentication (API key + private key)
  - Rate limiting (0.2s between requests)
  - Retry strategy with backoff
  - Pagination support
  - **Event Candlesticks API** (the key endpoint that works for weather markets)
  - Trades API (fallback)
- [x] `src/kalshi/schemas.py` - Pydantic models for:
  - Series, Market, Candle, Trade
  - CandlestickResponse, EventCandlestickResponse
  - MarketsResponse, TradesResponse

### 2.3 Weather Clients
- [x] `src/weather/visual_crossing.py` - Station-pinned 5-minute observations
- [x] `src/weather/nws.py` - NWS CLI/CF6/ADS settlement data

### 2.4 Ingestion Scripts
- [x] `scripts/backfill_kalshi_markets.py` - Markets metadata ingestion
- [x] `scripts/backfill_kalshi_candles.py` - Dual-source candle backfill:
  - `--source api_event` - From Event Candlesticks API
  - `--source trades` - From trades aggregation
  - `--source both` - Both sources (default)
- [x] `scripts/ingest_vc_minutes.py` - Visual Crossing observations
- [x] `scripts/ingest_nws_settlement.py` - NWS settlement data

### 2.5 Database Schema Features
- [x] Dual storage for candles with `source` column ('api_event' | 'trades')
- [x] Composite primary key: `(ticker, bucket_start, source)`
- [x] Migration script: `scripts/migrate_candles_add_source.py`

### 2.6 Tests
- [x] 57 tests passing (pytest)

---

## 3. Key Technical Discoveries

### 3.1 Event Candlesticks API Works for Weather Markets
The **Event Candlesticks** endpoint works for weather markets:
```
GET /series/{series}/events/{event}/candlesticks?start_ts=..&end_ts=..&period_interval=1
```

Returns all brackets in one call (~600-700 candles per market per event).

**Important:** Per-market candlesticks (`/series/{series}/markets/{ticker}/candlesticks`) return empty for weather markets - must use Event endpoint.

### 3.2 API Response Format
`market_candlesticks` is a **LIST of lists** parallel to `market_tickers`, NOT a dict:
```json
{
  "market_tickers": ["TICKER1", "TICKER2", ...],
  "market_candlesticks": [
    [candles for TICKER1...],
    [candles for TICKER2...],
  ],
  "adjusted_end_ts": ...
}
```

### 3.3 Pagination
- API paginates **backwards** using `adjusted_end_ts`
- Must track seen timestamps to avoid infinite loops
- `adjusted_end_ts` must be LESS than current `end_ts` to continue

---

## 4. Backfill Plan

### 4.1 Cities & Series Tickers

| City | Series Ticker | Airport Station | Timezone |
|------|---------------|-----------------|----------|
| Austin | KXHIGHAUS | KAUS | America/Chicago |
| Chicago | KXHIGHCHI | KMDW | America/Chicago |
| Denver | KXHIGHDEN | KDEN | America/Denver |
| Los Angeles | KXHIGHLA | KLAX | America/Los_Angeles |
| Miami | KXHIGHMIA | KMIA | America/New_York |
| Philadelphia | KXHIGHPHL | KPHL | America/New_York |

**Note:** NYC (KXHIGHNY) is EXCLUDED due to high forward-fill rates in Visual Crossing data.

### 4.2 Backfill Sequence

Execute in this order:

#### Step 1: Markets Metadata (All Cities)
```bash
# Run for each city
python scripts/backfill_kalshi_markets.py --series KXHIGHAUS --days 365
python scripts/backfill_kalshi_markets.py --series KXHIGHCHI --days 365
python scripts/backfill_kalshi_markets.py --series KXHIGHDEN --days 365
python scripts/backfill_kalshi_markets.py --series KXHIGHLA --days 365
python scripts/backfill_kalshi_markets.py --series KXHIGHMIA --days 365
python scripts/backfill_kalshi_markets.py --series KXHIGHPHL --days 365
```

#### Step 2: Candles (All Cities, Both Sources)
```bash
# Run for each city - both API and trades sources
python scripts/backfill_kalshi_candles.py --series KXHIGHAUS --source both
python scripts/backfill_kalshi_candles.py --series KXHIGHCHI --source both
python scripts/backfill_kalshi_candles.py --series KXHIGHDEN --source both
python scripts/backfill_kalshi_candles.py --series KXHIGHLA --source both
python scripts/backfill_kalshi_candles.py --series KXHIGHMIA --source both
python scripts/backfill_kalshi_candles.py --series KXHIGHPHL --source both
```

#### Step 3: Visual Crossing Weather Observations
```bash
# Backfill weather observations (use appropriate date range)
python scripts/ingest_vc_minutes.py --station KAUS --start-date 2024-01-01 --end-date 2025-11-26
python scripts/ingest_vc_minutes.py --station KMDW --start-date 2024-01-01 --end-date 2025-11-26
python scripts/ingest_vc_minutes.py --station KDEN --start-date 2024-01-01 --end-date 2025-11-26
python scripts/ingest_vc_minutes.py --station KLAX --start-date 2024-01-01 --end-date 2025-11-26
python scripts/ingest_vc_minutes.py --station KMIA --start-date 2024-01-01 --end-date 2025-11-26
python scripts/ingest_vc_minutes.py --station KPHL --start-date 2024-01-01 --end-date 2025-11-26
```

#### Step 4: NWS Settlement Data
```bash
# Backfill NWS settlement data for all cities
python scripts/ingest_nws_settlement.py --all-cities --start-date 2024-01-01 --end-date 2025-11-26
```

### 4.3 Expected Data Volumes

After full backfill (~365 days):

| Data Type | Per City | Total (6 Cities) |
|-----------|----------|------------------|
| Markets | ~2,190 (6 brackets × 365 days) | ~13,140 |
| Candles (api_event) | ~1,000,000+ | ~6,000,000+ |
| Candles (trades) | Variable | Variable |
| Weather Obs | ~105,120 (288/day × 365) | ~630,720 |
| Settlement | ~365 | ~2,190 |

---

## 5. Gap Analysis & Data Continuity

### 5.1 Current Gaps

| City | Markets Gap | Candles Gap | Weather Gap | Settlement Gap |
|------|-------------|-------------|-------------|----------------|
| Chicago | Missing < 2025-11-19 | Missing < 2025-11-18 | Missing all except 2025-11-25 | Missing all except 2025-11-25 |
| Austin | All missing | All missing | All missing | All missing |
| Denver | All missing | All missing | All missing | All missing |
| Los Angeles | All missing | All missing | All missing | All missing |
| Miami | All missing | All missing | All missing | All missing |
| Philadelphia | All missing | All missing | All missing | All missing |

### 5.2 Recommended Backfill Strategy

1. **Start Fresh for Non-Chicago Cities**: Run full backfill from 2024-01-01
2. **Extend Chicago Data**: Backfill Chicago from 2024-01-01 to 2025-11-18
3. **Continuous Going Forward**: Set up daily cron jobs to keep data current

### 5.3 Data Quality Checks After Backfill

Run these queries to verify no gaps:

```sql
-- Check for date gaps in markets
SELECT city, event_date,
       LAG(event_date) OVER (PARTITION BY city ORDER BY event_date) as prev_date,
       event_date - LAG(event_date) OVER (PARTITION BY city ORDER BY event_date) as gap_days
FROM (SELECT DISTINCT city, event_date FROM kalshi.markets) m
WHERE event_date - LAG(event_date) OVER (PARTITION BY city ORDER BY event_date) > 1;

-- Check for gaps in weather observations
SELECT loc_id, DATE(ts_utc) as obs_date,
       COUNT(*) as obs_count
FROM wx.minute_obs
GROUP BY loc_id, DATE(ts_utc)
HAVING COUNT(*) < 288  -- Expected 288 per day for 5-min intervals
ORDER BY loc_id, obs_date;

-- Check for missing settlement days
SELECT city, date_local,
       LAG(date_local) OVER (PARTITION BY city ORDER BY date_local) as prev_date
FROM wx.settlement
WHERE date_local - LAG(date_local) OVER (PARTITION BY city ORDER BY date_local) > 1;
```

---

## 6. Next Steps: Option 2 Feature Views

### 6.1 Prerequisites
1. Complete backfill for all 6 cities
2. Verify data quality (no gaps)
3. Create `feature` schema

### 6.2 Option 2 Implementation Plan

Per `docs/2_instructions_further_option2.md`:

#### Phase A: City-Time Grid View (`feature.option2_city_5m`)
- Grain: `(city, event_date, ts_utc)` at 5-minute resolution
- Join: `wx.minute_obs` + `wx.forecast_snapshot` + `wx.settlement`
- Features:
  - Time features: `minutes_since_midnight_local`, `minutes_to_close`, `session_phase`
  - Raw weather: `temp_f`, `humidity`, `dew_f`, `windspeed_mph`, `ffilled`
  - Dynamics: `temp_5m_change`, `temp_15m_change`, `temp_rolling_std_30m`, etc.
  - Forecast comparison: `temp_fcst_hour_f`, `temp_fcst_hour_err`
  - Nowcast: `tmax_nowcast_simple`, `delta_nowcast_vs_basis`, `nowcast_zscore`

#### Phase B: Bracket-Level View (`feature.option2_city_bin_5m`)
- Grain: `(city, event_date, ts_utc, ticker)`
- Join: `feature.option2_city_5m` + `kalshi.markets` + `kalshi.candles_1m`
- Features:
  - Weather features (inherited from View A)
  - Market features: `price_open`, `price_close`, `volume_5m`, `p_mkt_yes`
  - Geometry: `dist_nowcast_to_lower`, `is_bin_straddling_nowcast`, etc.
  - Labels: `tmax_final`, `bin_resolves_yes`

### 6.3 Additional Tables Needed

Before Option 2:
1. `wx.forecast_snapshot` - VC historical forecasts with `forecastBasisDate`
2. `wx.hourly_fcst_basis0` - Hourly forecast values for intraday comparison
3. `sim.run` and `sim.trade` - For backtest results

### 6.4 Estimated Timeline (No Dates, Just Sequence)

1. **Backfill Phase** - Run all backfill scripts for 6 cities
2. **Data Validation** - Run gap checks, verify counts
3. **Schema Extension** - Create `wx.forecast_snapshot`, `wx.hourly_fcst_basis0`
4. **Forecast Ingestion** - Implement VC historical forecast backfill
5. **Feature View A** - Implement `feature.option2_city_5m`
6. **Feature View B** - Implement `feature.option2_city_bin_5m`
7. **Sim Schema** - Create `sim.run`, `sim.trade`
8. **Backtest Harness** - Implement Option 2 strategy backtesting

---

## 7. Files Reference

### 7.1 Core Source Files
- `src/db/__init__.py` - Database connection
- `src/db/models.py` - ORM models
- `src/kalshi/client.py` - Kalshi API client
- `src/kalshi/schemas.py` - Pydantic schemas
- `src/weather/visual_crossing.py` - VC client
- `src/weather/nws.py` - NWS client

### 7.2 Scripts
- `scripts/backfill_kalshi_markets.py`
- `scripts/backfill_kalshi_candles.py` (supports `--source api_event|trades|both`)
- `scripts/ingest_vc_minutes.py`
- `scripts/ingest_nws_settlement.py`
- `scripts/migrate_candles_add_source.py`

### 7.3 Documentation
- `CLAUDE.md` - Project instructions
- `docs/1_instructions_to_start.md` - Phase 1 spec
- `docs/2_instructions_further_option2.md` - Option 2 spec
- `docs/PLANNING_2025-11-26_144243.md` - This document

---

## 8. Quick Resume Commands

When continuing this project:

```bash
# Start database
cd /home/halsted/weather_updated
docker compose up -d

# Verify connection
python -c "from src.db import get_engine; print(get_engine().connect())"

# Check current data state
python scripts/check_data_state.py  # (to be created)

# Run tests
python -m pytest tests/ -v --tb=short

# Continue backfill (example for Austin)
python scripts/backfill_kalshi_markets.py --series KXHIGHAUS --days 365
python scripts/backfill_kalshi_candles.py --series KXHIGHAUS --source both
```

---

## 9. Known Issues & Gotchas

1. **Event Candlesticks vs Market Candlesticks**: Weather markets ONLY work with Event Candlesticks endpoint
2. **Pagination Direction**: API paginates backwards from `end_ts`
3. **NYC Exclusion**: NYC is excluded due to poor VC data quality (high forward-fill rates)
4. **Timezone Handling**: Markets settle on LOCAL date, but candles are in UTC
5. **DST Considerations**: Be careful around DST transitions for date alignment

---

## 10. Environment Variables Required

```bash
# .env file contents
DB_URL=postgresql://kalshi:kalshi@localhost:5434/kalshi
KALSHI_API_KEY=<your-api-key>
KALSHI_PRIVATE_KEY_PATH=/path/to/private_key.pem
VISUAL_CROSSING_API_KEY=<your-vc-key>
```

---

*End of Planning Document*
